# Increase context length for Ollama models
https://localai.hashnode.dev/how-to-increase-ollama-models-context-length-from-2048

